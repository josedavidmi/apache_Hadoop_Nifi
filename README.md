# ğŸš€ Hadoop Cluster con Docker Compose (incluye Airflow y NiFi)

Este repositorio levanta un **mini-ecosistema Big Data en local** usando **Docker Compose**, incluyendo:

- **HDFS**: NameNode + mÃºltiples DataNodes  
- **YARN**: ResourceManager + NodeManagers  
- **History Server**: historial de jobs MapReduce completados  
- **Apache Airflow**: orquestaciÃ³n de pipelines (con **Postgres** como backend)  
- **Apache NiFi**: ingesta y gestiÃ³n de flujos de datos  

Todo corre en contenedores separados y conectados dentro de una red Docker comÃºn (por ejemplo `cluster_net`).

---

## ğŸ“¦ Requisitos

- Docker Desktop (o Docker Engine) instalado
- Docker Compose disponible (`docker compose ...`)

---

## ğŸ—‚ï¸ Estructura del proyecto

Ejemplo tÃ­pico:

```text
project/
â”œâ”€ docker-compose.yml
â”œâ”€ env
â”œâ”€ dags/
â””â”€ volumes/           (creados automÃ¡ticamente por Docker)
